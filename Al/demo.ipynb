{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import quaternion\n",
    "import re\n",
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "\n",
    "def get_box(file):\n",
    "    x, y, z = [], [], []\n",
    "    x, y, z = file['x'],file['y'],file['z']\n",
    "    x1,y1,z1 = min(x), min(y), min(z)\n",
    "    x2,y2,z2 = max(x), max(y), max(z)\n",
    "    return(x1,x2,y1,y2,z1,z2)\n",
    "\n",
    "def length_square(A1,A2):\n",
    "    A1,A2 = list(A1),list(A2)\n",
    "    x1,x2,y1,y2,z1,z2 = float(A1[3]),float(A2[3]),float(A1[4]),float(A2[4]),float(A1[5]),float(A2[5])\n",
    "    dx = x1 - x2\n",
    "    dy = y1 - y2\n",
    "    dz = z1 - z2\n",
    "    length2 = dx**2+dy**2+dz**2\n",
    "    return length2\n",
    "\n",
    "def readpdb(pdb):\n",
    "    inputfile = str(pdb)\n",
    "    outputfile = inputfile.strip(\".pdb\")\n",
    "    with open(inputfile,'r') as fp:\n",
    "        content = fp.readlines()\n",
    "        linesnumber = len(content)\n",
    "    lines = [] \n",
    "    with open(outputfile+'.txt','w') as fp_w:\n",
    "        for i in range (linesnumber):\n",
    "            # Split the line into individual values (assuming they are separated by spaces)\n",
    "            values = content[i].split() if content[i].strip() != '' else None\n",
    "            if values == None:\n",
    "                continue\n",
    "            # Extract values based on their positions in the format string\n",
    "            if (values[0]=='ATOM' or values[0] == 'HETATM'):\n",
    "                value1 = values[2] #atom_label\n",
    "                value2 = values[3] #res_name\n",
    "                value3 = float(values[5]) #x\n",
    "                value4 = float(values[6]) #y\n",
    "                value5 = float(values[7]) #z\n",
    "                value6 = values[10] #atom_note\n",
    "                value7 = int(values[4])\n",
    "            # Format the values using the specified format string\n",
    "                newline = \"%7s%7s%5d%8.3f%8.3f%8.3f%7s\" % (\n",
    "                    value1, value2, value7,value3, value4, value5, value6\n",
    "                    )\n",
    "     \n",
    "                lines.append(newline+'\\n')\n",
    "        fp_w.writelines(lines)\n",
    "    data = pd.read_csv(outputfile+'.txt',sep='\\s+',names=['Atom_label','Residue','Res_number','x','y','z','Note'])\n",
    "    return data\n",
    "\n",
    "def normalize_vector(v):\n",
    "    norm_v=v/np.linalg.norm(v)\n",
    "    return norm_v\n",
    "\n",
    "def findTOPinlinker(df,defined_atom_type):\n",
    "    matching_indices = df[df['Atom_label'] == defined_atom_type].index.tolist()\n",
    "    count_ATOMS = len(matching_indices)\n",
    "    print('\\n'+str(count_ATOMS)+' top points in ligand file')\n",
    "    return matching_indices\n",
    "\n",
    "def findtop_frame(df,defined_ATOM):\n",
    "    matching_indices = df[df['Atom_label'] == defined_ATOM].index.tolist()\n",
    "    count_ATOMS = len(matching_indices)\n",
    "    print('\\n'+str(count_ATOMS)+' top points in framework')\n",
    "    return count_ATOMS\n",
    "\n",
    "def get_linker_number(list,length):\n",
    "    count = 0\n",
    "    for i in list:\n",
    "        if (length-1) < i <(length+1):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def find_points_in_radius(points, center, radius):\n",
    "    points_identity = points.iloc[:, [0,1,2,5]]\n",
    "    points_positions = np.array(points.loc[:, ['x','y','z']])\n",
    "    center = np.array(center)\n",
    "    distances = np.linalg.norm(points_positions - center, axis=1)\n",
    "    indices = np.where(distances <= radius)[0]\n",
    "    return points[indices]\n",
    "\n",
    "def search_unique_vector(df1,MM_l):\n",
    "    vector = []\n",
    "    points_n = df1.shape[0]\n",
    "    for i in range(points_n):            \n",
    "        for j in range(points_n):\n",
    "            x = round(length_square(df1.loc[i],df1.loc[j]))\n",
    "            if ( x == round(MM_l)):\n",
    "                point_A_frame =  np.asarray(df1.loc[i,['x','y','z']],dtype = float)\n",
    "                point_B_frame =  np.asarray(df1.loc[j,['x','y','z']],dtype = float)\n",
    "                v = point_B_frame -point_A_frame\n",
    "                vAB = np.round(v, 1)\n",
    "                vector.append(vAB)\n",
    "    unique_vector = np.unique(vector, axis=0, return_index=False)\n",
    "    unique_vector = pd.DataFrame(unique_vector,columns=['vx','vy','vz'])\n",
    "    return unique_vector\n",
    "\n",
    "def search_neighbor_vector(df1,i,MM_l):\n",
    "    neighbor_vector = []\n",
    "    points_n = df1.shape[0]         \n",
    "    for j in range(points_n):\n",
    "        x = round(length_square(df1.loc[i],df1.loc[j]))\n",
    "        if ( x == round(MM_l)):\n",
    "            point_A_frame =  np.asarray(df1.loc[i,['x','y','z']],dtype = float)\n",
    "            point_B_frame =  np.asarray(df1.loc[j,['x','y','z']],dtype = float)\n",
    "            v = point_B_frame -point_A_frame\n",
    "            vAB = np.round(v, 1)\n",
    "            neighbor_vector.append(vAB)\n",
    "    neighbor_vector = pd.DataFrame(neighbor_vector,columns=['vx','vy','vz'])\n",
    "    return neighbor_vector\n",
    "\n",
    "def filtered_term_vector(df1,MM_l):\n",
    "    points_n = df1.shape[0] \n",
    "    term_vector = []\n",
    "    true_indices = []\n",
    "    for i in range(points_n):\n",
    "        unique_vector = search_unique_vector(df1,MM_l)\n",
    "        neighbor_vector = search_neighbor_vector(df1,i,MM_l)\n",
    "        df_vector = pd.concat([unique_vector,neighbor_vector],ignore_index=False)\n",
    "        filtered_vector = df_vector.drop_duplicates(keep=False)\n",
    "        term_vector.append(filtered_vector.to_numpy())\n",
    "        true_indices.append(filtered_vector.index)\n",
    "    return [term_vector,true_indices]\n",
    "\n",
    "def calculate_q_rotation_with_axis_degree(axis,theta): #axis is HE---HE ,theta from O1--AXIS--O1'\n",
    "    w = theta/2\n",
    "    s = np.sin(w)\n",
    "    q_real= np.array([np.cos(w)])\n",
    "    q_ijk = s*axis\n",
    "    q_r = np.concatenate([q_real,q_ijk])\n",
    "    q_r = quaternion.from_float_array(q_r)\n",
    "    return q_r\n",
    "\n",
    "def calculate_q_rotation_with_vectors(p1,p2):\n",
    "    q1 = quaternion.from_vector_part(p1)\n",
    "    q2 = quaternion.from_vector_part(p2)\n",
    "    r = q2*q1.conjugate()\n",
    "    return r\n",
    "\n",
    "def calculate_angle_rad(axis,p1, p2):\n",
    "    axis = normalize_vector(axis)\n",
    "    a_square=np.linalg.norm(p1)*np.linalg.norm(p1)-np.dot(p1,axis)*np.dot(p1,axis)\n",
    "    b_square=np.linalg.norm(p2)*np.linalg.norm(p2)-np.dot(p2,axis)*np.dot(p2,axis)\n",
    "    c_square=np.linalg.norm(p2-p1)*np.linalg.norm(p2-p1)\n",
    "    a,b = np.sqrt(a_square),np.sqrt(b_square)\n",
    "    cos_theta = (a_square+b_square-c_square)/(2*a*b)\n",
    "    print(cos_theta,a_square,b_square,c_square,axis,p1,p2)\n",
    "    cos_theta = np.clip(cos_theta,-1,1)\n",
    "    theta_rad = np.arccos(cos_theta)\n",
    "    print(theta_rad)\n",
    "    return theta_rad\n",
    "\n",
    "def points_generator(x_num,y_num,z_num,dx_value,dy_value,dz_value): \n",
    "    '''this function is to generate a group of 3d SCATTER defined by user for further grouping points'''\n",
    "    dx = dx_value*np.array([[1,0,0]]) #dx_value works as a scalar\n",
    "    dy = dy_value*np.array([[0,1,0]])\n",
    "    dz = dz_value*np.array([[0,0,1]])\n",
    "    # add x layer\n",
    "    points = np.array([[0,0,0]])\n",
    "    for i in range(0,x_num+1):\n",
    "        points = np.concatenate((points,i*dx),axis=0)\n",
    "    # add y layer\n",
    "    points_x =points\n",
    "    for i in range(0,y_num+1):\n",
    "        points = np.concatenate((points,points_x+i*dy),axis = 0)\n",
    "    # add z layer \n",
    "    points_xy = points\n",
    "    for i in range(0,z_num+1):\n",
    "        points = np.concatenate((points,points_xy+i*dz),axis = 0)\n",
    "    points = np.unique(points, axis = 0)\n",
    "    return points\n",
    "\n",
    "def find_overlapped_3D_array(array1,array2):\n",
    "    set1 = set(map(tuple, array1.reshape(-1, array1.shape[-1])))\n",
    "    set2 = set(map(tuple, array2.reshape(-1, array2.shape[-1])))\n",
    "    # Find intersection of sets\n",
    "    overlapped_elements = set1.intersection(set2)\n",
    "    # Convert back to numpy array\n",
    "    overlapped_array = np.array(list(overlapped_elements)).reshape(-1, array1.shape[-1])\n",
    "    return overlapped_array\n",
    "\n",
    "def groupA_one_step_to_groupB(first_B,group_A,d,points):\n",
    "    point_dx = group_A+d\n",
    "    group_B = first_B\n",
    "    for i in range(group_A.shape[0]):\n",
    "        point = np.reshape(point_dx[i], (1, 3))\n",
    "        group_B = np.concatenate((group_B,point),axis = 0) if np.all(points == point, axis=1).any() else group_B\n",
    "        group_B = np.unique(group_B,axis=0)\n",
    "    return group_B\n",
    "\n",
    "def groupA_one_step_to_groupA(group_A,d,points):\n",
    "    point_dx = group_A+d\n",
    "    for i in range(group_A.shape[0]):\n",
    "        point = np.reshape(point_dx[i], (1, 3))\n",
    "        group_A = np.concatenate((group_A,point),axis = 0) if np.all(points == point, axis=1).any() else group_A\n",
    "        group_A = np.unique(group_A,axis=0)\n",
    "    return group_A\n",
    "\n",
    "def group_points_AB(x_num,y_num,z_num,dx_value,dy_value,dz_value):\n",
    "   points=points_generator(x_num,y_num,z_num,dx_value,dy_value,dz_value)\n",
    "   O = np.array([[0,0,0]])\n",
    "   dx = dx_value*np.array([[1,0,0]]) #dx_value works as a scalar\n",
    "   dy = dy_value*np.array([[0,1,0]])\n",
    "   dz = dz_value*np.array([[0,0,1]])\n",
    "\n",
    "   first_A = O\n",
    "   first_B = O+dy\n",
    "   group_A = first_A\n",
    "   group_B = first_B\n",
    "\n",
    "   for i in range(points.shape[0]):\n",
    "      if group_A.shape[0]+group_B.shape[0] == points.shape[0]:\n",
    "         break\n",
    "      else:\n",
    "         group_B_dx = groupA_one_step_to_groupB(first_B,group_A,dx,points)\n",
    "         group_B_dy = groupA_one_step_to_groupB(first_B,group_A,dy,points)\n",
    "         group_B_dz = groupA_one_step_to_groupA(group_B,dz,points)\n",
    "         group_B_dxyz = [group_B,group_B_dx,group_B_dy,group_B_dz]\n",
    "         group_B = np.concatenate([arr for arr in group_B_dxyz if arr is not None],axis = 0) \n",
    "         group_B = np.unique(group_B,axis=0)\n",
    "         group_A_dx = groupA_one_step_to_groupB(first_A,group_B,dx,points)\n",
    "         group_A_dy = groupA_one_step_to_groupB(first_A,group_B,dy,points)\n",
    "         group_A_dz = groupA_one_step_to_groupA(group_A,dz,points)\n",
    "         group_A_dxyz = [group_A,group_A_dx,group_A_dy,group_A_dz]\n",
    "         group_A = np.concatenate([arr for arr in group_A_dxyz if arr is not None],axis = 0)\n",
    "         group_A = np.unique(group_A,axis=0)\n",
    "   \n",
    "   return group_A,group_B\n",
    "\n",
    "def get_center_point_of_face(p1_face,p2_face,p3_face):\n",
    "    center_point = (normalize_vector(p1_face)+\n",
    "                              normalize_vector(p2_face)+\n",
    "                              normalize_vector(p2_face))/3\n",
    "    return center_point\n",
    "\n",
    "def find_solution(pAl1,pAl2,pAl1_1,pAl1_2,pAl1_3):\n",
    "    Al1_Al2 = pAl2-pAl1\n",
    "    vAl1_Al2 = normalize_vector(Al1_Al2)\n",
    "    v12_1,v12_2,v12_3  = pAl1_1-pAl1,pAl1_2-pAl1,pAl1_3-pAl1\n",
    "    v12_1,v12_2,v12_3= normalize_vector(v12_1),normalize_vector(v12_2),normalize_vector(v12_3)                        \n",
    "    arr_1_2=np.vstack((v12_1,v12_2,v12_3))\n",
    "    arr_1_2 = arr_1_2.astype(np.float64)\n",
    "    vAl1_Al2 = vAl1_Al2.astype(np.float64)\n",
    "    solution_1_2=np.dot(vAl1_Al2,np.linalg.inv(arr_1_2))\n",
    "    return solution_1_2,arr_1_2\n",
    "\n",
    "def get_rotated_array(arr,q):\n",
    "    q_arr= quaternion.from_vector_part(arr)\n",
    "    rotated_q_arr = q*q_arr*q.inverse()\n",
    "    rotated_arr = quaternion.as_vector_part(rotated_q_arr)\n",
    "    return rotated_arr\n",
    "\n",
    "def calculate_node(Metal_file,linker_cut_count,Residue_name,group_A,group_B,new_node_A,new_node_B):\n",
    "#rotate as group, translate as group \n",
    "    Metal_count = linker_cut_count\n",
    "    zero_lines = new_node_A.shape[0]\n",
    "    df_node = pd.DataFrame()\n",
    "    for i in group_A:\n",
    "        new_positions=new_node_A+i\n",
    "        df_left = pd.DataFrame(np.zeros((zero_lines, 4)),columns = ['Atom_label','Residue','Res_number','Note'])\n",
    "        df_left['Atom_label'] = Metal_file['Atom_label']\n",
    "        df_left['Residue'] = Metal_file['Residue']\n",
    "        df_left['Res_number'] = Metal_count\n",
    "        df_left['Note'] = Metal_file['Note']\n",
    "        df_right = pd.DataFrame(new_positions,columns = ['x','y','z'])\n",
    "        df = pd.concat([df_left,df_right],axis = 1, join = 'outer') \n",
    "        df_node = pd.concat([df_node,df],ignore_index=True, join = 'outer')\n",
    "        Metal_count += 1\n",
    "    for i in group_B:\n",
    "        new_positions=new_node_B+i\n",
    "        \n",
    "        df_left = pd.DataFrame(np.zeros((zero_lines, 4)),columns = ['Atom_label','Residue','Res_number','Note'])\n",
    "        df_left['Atom_label'] = Metal_file['Atom_label']\n",
    "        df_left['Residue'] = Metal_file['Residue']\n",
    "        df_left['Res_number'] = Metal_count\n",
    "        df_left['Note'] = Metal_file['Note']\n",
    "        df_right = pd.DataFrame(new_positions,columns = ['x','y','z'])\n",
    "        df = pd.concat([df_left,df_right],axis = 1, join = 'outer') \n",
    "        df_node = pd.concat([df_node,df],ignore_index=True, join = 'outer')\n",
    "        Metal_count += 1\n",
    "    \n",
    "    return df_node\n",
    "\n",
    "def get_box_dimension(file):\n",
    "    x1,x2,y1,y2,z1,z2 = get_box(file)\n",
    "    dx,dy,dz = abs(x1-x2), abs(y1-y2), abs(z1-z2)\n",
    "    dimension = [str(round(dx,5)), str(round(dy,5)),str(round(dz,5))]\n",
    "    s = ' '.join(dimension)\n",
    "    return(s)\n",
    "\n",
    "def outgro(df_all,output,Hecount):\n",
    "    with open(output+'.txt', 'r') as f:\n",
    "        # Read the lines from the file\n",
    "        lines = f.readlines()\n",
    "        atoms_number = len(lines)\n",
    "    newgro = []\n",
    "    with open(output+'.gro', 'w') as fp:\n",
    "        newgro.append(\"generated by MOF_BUILD\"+'\\n'+str(atoms_number-Hecount)+'\\n')\n",
    "        # Iterate over each line in the input file\n",
    "        for i in range (Hecount,atoms_number):\n",
    "            # Split the line into individual values (assuming they are separated by spaces)\n",
    "            values = lines[i].split()\n",
    "            # Extract values based on their positions in the format string\n",
    "            #value1 = 'ATOM'\n",
    "            value_atom_number = int(i+1-Hecount) #atom_number\n",
    "            value_label = values[0] #atom_label\n",
    "            value_resname = values[1] #residue_name\n",
    "            value_resnumber = int(values[2]) #residue number\n",
    "            value_x = float(values[4])/10 #x      \n",
    "            value_y = float(values[5])/10 #y\n",
    "            value_z = float(values[6])/10 #z\n",
    "            #value11 = values[6] #note\n",
    "            # Format the values using the specified format string\n",
    "            formatted_line = \"%5d%-5s%5s%5d%8.4f%8.4f%8.4f\" % (\n",
    "                        value_resnumber, value_resname, value_label, value_atom_number, value_x, value_y, value_z) \n",
    "            newgro.append(formatted_line+'\\n')        \n",
    "\n",
    "        tail = get_box_dimension(df_all.iloc[4:6])+'\\n'\n",
    "        newgro.append(tail)\n",
    "        fp.writelines(newgro)\n",
    "\n",
    "def outxyz(output,Hecount):\n",
    "    with open(output+'.txt', 'r') as f:\n",
    "        # Read the lines from the file\n",
    "        lines = f.readlines()\n",
    "        atoms_number = len(lines)-Hecount\n",
    "\n",
    "    newxyz = []\n",
    "    with open(output+'.xyz', 'w') as fp:\n",
    "        newxyz.append(str(atoms_number)+'\\n'+\"generated by MOF_BUILD\"+'\\n')\n",
    "        # Iterate over each line in the input file\n",
    "        for i in range (Hecount,atoms_number):\n",
    "            # Split the line into individual values (assuming they are separated by spaces)\n",
    "            values = lines[i].split()\n",
    "            # Extract values based on their positions in the format string\n",
    "            #value1 = 'ATOM'\n",
    "            #value_atom_number = int(i+1) #atom_number\n",
    "            value_label = values[0] #atom_label\n",
    "            value_label = re.sub(r'\\d', '', value_label)\n",
    "            #value_resname = values[1] #residue_name\n",
    "            #value_resnumber = int(values[2]) #residue number\n",
    "            value_x = float(values[4]) #x      \n",
    "            value_y = float(values[5]) #y\n",
    "            value_z = float(values[6]) #z\n",
    "            #value11 = values[6] #note\n",
    "            # Format the values using the specified format string\n",
    "            formatted_line = \"%-5s%8.3f%8.3f%8.3f\" % (\n",
    "                        value_label, value_x, value_y, value_z\n",
    "            )        \n",
    "            newxyz.append(formatted_line+'\\n')        \n",
    "\n",
    "        fp.writelines(newxyz)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.90910488 -0.29143599  0.31053338] [ 0.03987703 -0.74301673 -0.725923  ]\n",
      "[ 1.00000000e+00 -5.55111512e-17  5.55111512e-17] [ 5.55111512e-17 -5.55111512e-17 -1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "textbook_Metal_file = readpdb('Al_Al.pdb')\n",
    "\n",
    "pAl1,pAl2,pAl3 = (textbook_Metal_file.loc[15, ['x','y','z']].to_numpy(),\n",
    "                  textbook_Metal_file.loc[8, ['x','y','z']].to_numpy(),\n",
    "                  textbook_Metal_file.loc[29, ['x','y','z']].to_numpy())    \n",
    "\n",
    "pAl1_1,pAl1_2,pAl1_3 =(textbook_Metal_file.loc[16, ['x','y','z']].to_numpy(),\n",
    "                          textbook_Metal_file.loc[17, ['x','y','z']].to_numpy(),\n",
    "                          textbook_Metal_file.loc[18, ['x','y','z']].to_numpy()) \n",
    "   \n",
    "solution_1_2,arr_1_2 = find_solution(pAl1,pAl2,pAl1_1,pAl1_2,pAl1_3)\n",
    "solution_1_3,arr_1_3 = find_solution(pAl1,pAl3,pAl1_1,pAl1_2,pAl1_3)\n",
    "print(solution_1_2,solution_1_3)\n",
    "print(np.dot(solution_1_2,arr_1_2),np.dot(solution_1_3,arr_1_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axis2(solution_1_2,arr_1_2,solution_1_3,arr_1_3):\n",
    "    axis1 = np.dot(solution_1_2,arr_1_2)\n",
    "    axis2 = np.dot(solution_1_3,arr_1_3)\n",
    "    q_axis = calculate_q_rotation_with_vectors(axis1,axis2)\n",
    "    dx = np.array([1,0,0])\n",
    "    axis0=quaternion.from_vector_part(dx)\n",
    "    new_axis = q_axis*axis0\n",
    "    new_axis_vector = quaternion.as_vector_part(new_axis)\n",
    "    print(new_axis_vector)\n",
    "    return new_axis_vector\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00 -5.55111512e-17 -1.00000000e+00]\n",
      "0.9999997620624731 0.9999995499368891 0.9999999999999998 4.758749975167327e-07 [1. 0. 0.] [-6.67360486e-04 -1.74656582e-04 -9.99999760e-01] [ 0.00000000e+00 -5.55111512e-17 -1.00000000e+00]\n",
      "0.000689836989931967\n",
      "[-6.67360486e-04 -1.74656582e-04 -9.99999760e-01] [ 0.00000000e+00 -5.55111512e-17 -1.00000000e+00] 0.000689836989931967\n"
     ]
    }
   ],
   "source": [
    "Metal_file=readpdb('test.pdb')\n",
    "axis1 = np.array([1,0,0])\n",
    "axis2 =  get_axis2(solution_1_2,arr_1_2,solution_1_3,arr_1_3)\n",
    "\n",
    "axis3 = np.cross(axis1,axis2)\n",
    "\n",
    "point_Al = Metal_file.loc[0, ['x','y','z']].to_numpy()\n",
    "p1,p2,p3 = (Metal_file.loc[1, ['x','y','z']].to_numpy()- point_Al,\n",
    "                                    Metal_file.loc[2, ['x','y','z']].to_numpy()- point_Al,\n",
    "                                    Metal_file.loc[3, ['x','y','z']].to_numpy()- point_Al )     \n",
    "p1,p2,p3=normalize_vector(p1),normalize_vector(p2),normalize_vector(p3)                         \n",
    "arr = np.vstack((p1,p2,p3))\n",
    "V1,V2 = np.dot(solution_1_2,arr),np.dot(solution_1_3,arr)\n",
    "V1,V2 = normalize_vector(V1),normalize_vector(V2)\n",
    "\n",
    "\n",
    "\n",
    "Al_node = Metal_file.loc[:,['x','y','z']].to_numpy() - point_Al  #MOVE center (Al this case) to (0,0,0)\n",
    "q1 = calculate_q_rotation_with_vectors(V1,axis1) \n",
    "q_V2 = quaternion.from_vector_part(V2)\n",
    "new_q_V2 = q1*q_V2\n",
    "new_V2 = quaternion.as_vector_part(new_q_V2)\n",
    "angle = calculate_angle_rad(axis1,new_V2,axis2)\n",
    "print(new_V2,axis2,angle)\n",
    "#q2 = calculate_q_rotation_with_axis_degree(axis1,angle)\n",
    "q2 = calculate_q_rotation_with_vectors(new_V2,axis2)\n",
    "#q3 = quaternion.from_float_array([0,0,0,-1])\n",
    "#dy dz rotate pi\n",
    "q3 = calculate_q_rotation_with_axis_degree(axis2,np.pi)*calculate_q_rotation_with_axis_degree(axis3,np.pi)\n",
    "q_A = q2*q1\n",
    "q_B = q3*q2*q1\n",
    "\n",
    "new_node_A = get_rotated_array(Al_node,q_A)\n",
    "new_node_B = get_rotated_array(Al_node,q_B)\n",
    "\n",
    "\n",
    "#df_node.to_csv('node.txt',header=None,sep='\\t',index=False)\n",
    "\n",
    "#outgro(df_node,'node',0)\n",
    "#outxyz('node',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_generator(x_num,y_num,z_num,dx_value,dy_value,dz_value): \n",
    "    '''this function is to generate a group of 3d SCATTER defined by user for further grouping points'''\n",
    "    dx = dx_value*np.array([[1,0,0]]) #dx_value works as a scalar\n",
    "    dy = dy_value*np.array([[0,1,0]])\n",
    "    dz = dz_value*np.array([[0,0,1]])\n",
    "    # add x layer\n",
    "    points = np.array([[0,0,0]])\n",
    "    for i in range(0,x_num+1):\n",
    "        points = np.concatenate((points,i*dx),axis=0)\n",
    "    # add y layer\n",
    "    points_x =points\n",
    "    for i in range(0,y_num+1):\n",
    "        points = np.concatenate((points,points_x+i*dy),axis = 0)\n",
    "    # add z layer \n",
    "    points_xy = points\n",
    "    for i in range(0,z_num+1):\n",
    "        points = np.concatenate((points,points_xy+i*dz),axis = 0)\n",
    "    points = np.unique(points, axis = 0)\n",
    "    return points\n",
    "\n",
    "def find_overlapped_3D_array(array1,array2):\n",
    "    set1 = set(map(tuple, array1.reshape(-1, array1.shape[-1])))\n",
    "    set2 = set(map(tuple, array2.reshape(-1, array2.shape[-1])))\n",
    "    # Find intersection of sets\n",
    "    overlapped_elements = set1.intersection(set2)\n",
    "    # Convert back to numpy array\n",
    "    overlapped_array = np.array(list(overlapped_elements)).reshape(-1, array1.shape[-1])\n",
    "    return overlapped_array\n",
    "\n",
    "def groupA_one_step_to_groupB(first_B,group_A,d,points):\n",
    "    point_dx = group_A+d\n",
    "    group_B = first_B\n",
    "    for i in range(group_A.shape[0]):\n",
    "        point = np.reshape(point_dx[i], (1, 3))\n",
    "        group_B = np.concatenate((group_B,point),axis = 0) if np.all(points == point, axis=1).any() else group_B\n",
    "        group_B = np.unique(group_B,axis=0)\n",
    "    return group_B\n",
    "\n",
    "def groupA_one_step_to_groupA(group_A,d,points):\n",
    "    point_dx = group_A+d\n",
    "    for i in range(group_A.shape[0]):\n",
    "        point = np.reshape(point_dx[i], (1, 3))\n",
    "        group_A = np.concatenate((group_A,point),axis = 0) if np.all(points == point, axis=1).any() else group_A\n",
    "        group_A = np.unique(group_A,axis=0)\n",
    "    return group_A\n",
    "\n",
    "def group_points_AB(x_num,y_num,z_num,dx_value,dy_value,dz_value):\n",
    "   points=points_generator(x_num,y_num,z_num,dx_value,dy_value,dz_value)\n",
    "   O = np.array([[0,0,0]])\n",
    "   dx = dx_value*np.array([[1,0,0]]) #dx_value works as a scalar\n",
    "   dy = dy_value*np.array([[0,1,0]])\n",
    "   dz = dz_value*np.array([[0,0,1]])\n",
    "\n",
    "   first_A = O\n",
    "   first_B = O+dy\n",
    "   group_A = first_A\n",
    "   group_B = first_B\n",
    "\n",
    "   for i in range(points.shape[0]):\n",
    "      if group_A.shape[0]+group_B.shape[0] == points.shape[0]:\n",
    "         break\n",
    "      else:\n",
    "         group_B_dx = groupA_one_step_to_groupB(first_B,group_A,dx,points)\n",
    "         group_B_dy = groupA_one_step_to_groupB(first_B,group_A,dy,points)\n",
    "         group_B_dz = groupA_one_step_to_groupA(group_B,dz,points)\n",
    "         group_B_dxyz = [group_B,group_B_dx,group_B_dy,group_B_dz]\n",
    "         group_B = np.concatenate([arr for arr in group_B_dxyz if arr is not None],axis = 0) \n",
    "         group_B = np.unique(group_B,axis=0)\n",
    "         group_A_dx = groupA_one_step_to_groupB(first_A,group_B,dx,points)\n",
    "         group_A_dy = groupA_one_step_to_groupB(first_A,group_B,dy,points)\n",
    "         group_A_dz = groupA_one_step_to_groupA(group_A,dz,points)\n",
    "         group_A_dxyz = [group_A,group_A_dx,group_A_dy,group_A_dz]\n",
    "         group_A = np.concatenate([arr for arr in group_A_dxyz if arr is not None],axis = 0)\n",
    "         group_A = np.unique(group_A,axis=0)\n",
    "   \n",
    "   return group_A,group_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = Metal_file\n",
    "beginning_point = point_Al\n",
    "v1_file = V1\n",
    "v1_frame = axis1\n",
    "v2_file = V2\n",
    "v2_frame = axis2\n",
    "\n",
    "def rotate_twice_linker(df_input,beginning_point,v1_file,v1_frame,v2_file,v2_frame):\n",
    "    arr = df_input.loc[:,['x','y','z']].to_numpy() - beginning_point #MOVE center (Al this case) to (0,0,0)\n",
    "    q1 = calculate_q_rotation_with_vectors(v1_file,v1_frame) \n",
    "    q_V2 = quaternion.from_vector_part(v2_file)\n",
    "    new_q_V2 = q1*q_V2\n",
    "    new_V2_file = quaternion.as_vector_part(new_q_V2)\n",
    "    #angle = calculate_angle_rad(v1_frame,new_V2_file,v2_frame)\n",
    "    #q2 = calculate_q_rotation_with_axis_degree(v1_frame,angle)\n",
    "    q2 = calculate_q_rotation_with_vectors(new_V2_file,v2_frame)\n",
    "    q_rotate = q2*q1\n",
    "    new_array = get_rotated_array(arr,q_rotate)\n",
    "    return new_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(616, 3) (594, 3)\n",
      "\n",
      "Time cost (s):   0:00:00.661627\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.datetime.now()\n",
    "x_num,y_num,z_num,dx_value,dy_value,dz_value = 10,10,10,3.31,16.8,15.94\n",
    "points = points_generator(x_num,y_num,z_num,dx_value,dy_value,dz_value)\n",
    "A_map_0 =  points_generator(x_num,y_num,z_num,2*dx_value,2*dy_value,dz_value)\n",
    "B_map_dx = A_map_0+dx_value*np.array([1,0,0])\n",
    "B_map_dy = A_map_0+dy_value*np.array([0,1,0])\n",
    "B_map = np.concatenate((B_map_dx,B_map_dy),axis=0)\n",
    "\n",
    "A_map_dx = B_map+dx_value*np.array([[1,0,0]])\n",
    "A_map = np.concatenate((A_map_0,A_map_dx),axis=0)\n",
    "B_map = np.concatenate((B_map,B_map_dx),axis=0)\n",
    "\n",
    "A_map,B_map = np.unique(A_map,axis=0),np.unique(B_map,axis=0)\n",
    "\n",
    "group_A = find_overlapped_3D_array(A_map,points)\n",
    "group_B = find_overlapped_3D_array(B_map,points)\n",
    "\n",
    "#group_A,group_B = group_points_AB(x_num,y_num,z_num,dx_value,dy_value,dz_value) #too slow to be used\n",
    "\n",
    "linker_cut_count,Residue_name = 1,'Al'\n",
    "df_node = calculate_node(Metal_file,linker_cut_count,Residue_name,group_A,group_B,new_node_A,new_node_B)\n",
    "df_node.to_csv('node.txt',header=None,sep='\\t',index=False)\n",
    "\n",
    "print(group_A.shape,group_B.shape )\n",
    "\n",
    "outgro(df_node,'node',0)\n",
    "outxyz('node',0)\n",
    "endTime = datetime.datetime.now()\n",
    "print('\\n'+\"Time cost (s):   \"+str(endTime-startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atom_label</th>\n",
       "      <th>Residue</th>\n",
       "      <th>Res_number</th>\n",
       "      <th>Note</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al</td>\n",
       "      <td>AL6</td>\n",
       "      <td>1</td>\n",
       "      <td>Al</td>\n",
       "      <td>29.790000</td>\n",
       "      <td>117.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DD2</td>\n",
       "      <td>AL6</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>28.981045</td>\n",
       "      <td>117.202887</td>\n",
       "      <td>0.005663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DD3</td>\n",
       "      <td>AL6</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>29.497004</td>\n",
       "      <td>118.177744</td>\n",
       "      <td>0.618768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DD4</td>\n",
       "      <td>AL6</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>30.045192</td>\n",
       "      <td>116.985825</td>\n",
       "      <td>0.602164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DD5</td>\n",
       "      <td>AL6</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>30.592964</td>\n",
       "      <td>117.998114</td>\n",
       "      <td>-0.011671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8465</th>\n",
       "      <td>DD3</td>\n",
       "      <td>AL6</td>\n",
       "      <td>1210</td>\n",
       "      <td>H</td>\n",
       "      <td>3.017004</td>\n",
       "      <td>100.222256</td>\n",
       "      <td>79.081232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8466</th>\n",
       "      <td>DD4</td>\n",
       "      <td>AL6</td>\n",
       "      <td>1210</td>\n",
       "      <td>H</td>\n",
       "      <td>3.565192</td>\n",
       "      <td>101.414175</td>\n",
       "      <td>79.097836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8467</th>\n",
       "      <td>DD5</td>\n",
       "      <td>AL6</td>\n",
       "      <td>1210</td>\n",
       "      <td>H</td>\n",
       "      <td>4.112964</td>\n",
       "      <td>100.401886</td>\n",
       "      <td>79.711671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8468</th>\n",
       "      <td>DD6</td>\n",
       "      <td>AL6</td>\n",
       "      <td>1210</td>\n",
       "      <td>H</td>\n",
       "      <td>3.626965</td>\n",
       "      <td>101.390748</td>\n",
       "      <td>80.296737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8469</th>\n",
       "      <td>DD7</td>\n",
       "      <td>AL6</td>\n",
       "      <td>1210</td>\n",
       "      <td>H</td>\n",
       "      <td>3.020869</td>\n",
       "      <td>100.234816</td>\n",
       "      <td>80.339232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8470 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Atom_label Residue  Res_number Note          x           y          z\n",
       "0            Al     AL6           1   Al  29.790000  117.600000   0.000000\n",
       "1           DD2     AL6           1    H  28.981045  117.202887   0.005663\n",
       "2           DD3     AL6           1    H  29.497004  118.177744   0.618768\n",
       "3           DD4     AL6           1    H  30.045192  116.985825   0.602164\n",
       "4           DD5     AL6           1    H  30.592964  117.998114  -0.011671\n",
       "...         ...     ...         ...  ...        ...         ...        ...\n",
       "8465        DD3     AL6        1210    H   3.017004  100.222256  79.081232\n",
       "8466        DD4     AL6        1210    H   3.565192  101.414175  79.097836\n",
       "8467        DD5     AL6        1210    H   4.112964  100.401886  79.711671\n",
       "8468        DD6     AL6        1210    H   3.626965  101.390748  80.296737\n",
       "8469        DD7     AL6        1210    H   3.020869  100.234816  80.339232\n",
       "\n",
       "[8470 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_node = df_node[df_node['Residue']=='AL6'].reset_index(drop=True)\n",
    "df1_node['Res_number']= (df1_node.index//7+1)\n",
    "df1_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atom_label</th>\n",
       "      <th>Residue</th>\n",
       "      <th>Res_number</th>\n",
       "      <th>Note</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O1</td>\n",
       "      <td>MOH</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>31.443880</td>\n",
       "      <td>118.458226</td>\n",
       "      <td>0.002750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H1</td>\n",
       "      <td>MOH</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>31.443745</td>\n",
       "      <td>119.446226</td>\n",
       "      <td>0.003095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O1</td>\n",
       "      <td>MOH</td>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>4.963880</td>\n",
       "      <td>17.658226</td>\n",
       "      <td>159.402750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H1</td>\n",
       "      <td>MOH</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>4.963745</td>\n",
       "      <td>18.646226</td>\n",
       "      <td>159.403095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O1</td>\n",
       "      <td>MOH</td>\n",
       "      <td>3</td>\n",
       "      <td>O</td>\n",
       "      <td>34.753880</td>\n",
       "      <td>135.258226</td>\n",
       "      <td>31.882750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>H1</td>\n",
       "      <td>MOH</td>\n",
       "      <td>1208</td>\n",
       "      <td>H</td>\n",
       "      <td>8.273745</td>\n",
       "      <td>149.353774</td>\n",
       "      <td>15.936905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>O1</td>\n",
       "      <td>MOH</td>\n",
       "      <td>1209</td>\n",
       "      <td>O</td>\n",
       "      <td>1.653880</td>\n",
       "      <td>83.141774</td>\n",
       "      <td>63.757250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>H1</td>\n",
       "      <td>MOH</td>\n",
       "      <td>1209</td>\n",
       "      <td>H</td>\n",
       "      <td>1.653745</td>\n",
       "      <td>82.153774</td>\n",
       "      <td>63.756905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>O1</td>\n",
       "      <td>MOH</td>\n",
       "      <td>1210</td>\n",
       "      <td>O</td>\n",
       "      <td>4.963880</td>\n",
       "      <td>99.941774</td>\n",
       "      <td>79.697250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>H1</td>\n",
       "      <td>MOH</td>\n",
       "      <td>1210</td>\n",
       "      <td>H</td>\n",
       "      <td>4.963745</td>\n",
       "      <td>98.953774</td>\n",
       "      <td>79.696905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2420 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Atom_label Residue  Res_number Note          x           y           z\n",
       "0            O1     MOH           1    O  31.443880  118.458226    0.002750\n",
       "1            H1     MOH           1    H  31.443745  119.446226    0.003095\n",
       "2            O1     MOH           2    O   4.963880   17.658226  159.402750\n",
       "3            H1     MOH           2    H   4.963745   18.646226  159.403095\n",
       "4            O1     MOH           3    O  34.753880  135.258226   31.882750\n",
       "...         ...     ...         ...  ...        ...         ...         ...\n",
       "2415         H1     MOH        1208    H   8.273745  149.353774   15.936905\n",
       "2416         O1     MOH        1209    O   1.653880   83.141774   63.757250\n",
       "2417         H1     MOH        1209    H   1.653745   82.153774   63.756905\n",
       "2418         O1     MOH        1210    O   4.963880   99.941774   79.697250\n",
       "2419         H1     MOH        1210    H   4.963745   98.953774   79.696905\n",
       "\n",
       "[2420 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_node = df_node[df_node['Residue']=='MOH'].reset_index(drop=True)\n",
    "df2_node['Res_number']= (df2_node.index//2+1)\n",
    "df2_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num,y_num,z_num,dx_value,dy_value,dz_value = 5,2,2,3,16,16\n",
    "dx = dx_value*np.array([1,0,0]) #dx_value works as a scalar\n",
    "dy = dy_value*np.array([0,1,0])\n",
    "dz = dz_value*np.array([0,0,1])\n",
    "points = points_generator(x_num,y_num,z_num,dx_value,dy_value,dz_value)\n",
    "\n",
    "def calculate_cos(v1,v2):\n",
    "    cos = np.dot(v1,v2)/(np.linalg.norm(v1)*np.linalg.norm(v2)) if np.linalg.norm(v2) != 0 else None\n",
    "    return cos\n",
    "\n",
    "\n",
    "body_diag=(dx+dy+dz).ravel() \n",
    "#box_size = (x_num*dx+y_num*dy+z_num*dz).ravel()\n",
    "points_A1 = find_overlapped_3D_array(points+body_diag,points)\n",
    "center_of_unitbox_points = points_A1-0.5*body_diag #Co position \n",
    "#print(center_of_unitbox_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "rotate porphyrin or other tetradentate linker to make it algin with dx and make Co position as parameter for 2nd rotate\n",
    "for further translation \n",
    "\n",
    "'''\n",
    "linker_file = readpdb('TCP.pdb')\n",
    "#O1 is the cross point\n",
    "O1,O2,O3 = linker_file.loc[54,['x','y','z']].to_numpy(),\\\n",
    "            linker_file.loc[57,['x','y','z']].to_numpy(),\\\n",
    "            linker_file.loc[51,['x','y','z']].to_numpy()\n",
    "Co = linker_file.loc[60,['x','y','z']].to_numpy()\n",
    "r1_vector_in_frame = normalize_vector(dx)\n",
    "r2_vector_in_frame = normalize_vector(dz)\n",
    "r1_vector_in_linker = normalize_vector(O2-O1)\n",
    "r2_vector_in_linker = normalize_vector(O3-O1)\n",
    "\n",
    "df_input = linker_file\n",
    "beginning_point = O1\n",
    "v1_file = r1_vector_in_linker\n",
    "v1_frame = r1_vector_in_frame\n",
    "v2_file = r2_vector_in_linker\n",
    "v2_frame = r2_vector_in_frame\n",
    "\n",
    "new_linker = rotate_twice_linker(df_input,beginning_point,v1_file,v1_frame,v2_file,v2_frame)\n",
    "rotated_new_linker = new_linker-O1+0.5*O2+0.5*O3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_linker(linker_file,linker_count,Residue_name,new_beginnings_array,new_linker):\n",
    "#translate by center points position, beginning point as CENTER OF PORPHYRIN like Co(body center of unit box)\n",
    "    zero_lines = new_linker.shape[0]\n",
    "    df_linker = pd.DataFrame()\n",
    "    for i in new_beginnings_array:\n",
    "        new_positions=new_linker+i\n",
    "        df_left = pd.DataFrame(np.zeros((zero_lines, 4)),columns = ['Atom_label','Residue','Res_number','Note'])\n",
    "        df_left['Atom_label'] = linker_file['Atom_label']\n",
    "        df_left['Residue'] = linker_file['Residue']\n",
    "        df_left['Res_number'] = linker_count\n",
    "        df_left['Note'] = linker_file['Note']\n",
    "        df_right = pd.DataFrame(new_positions,columns = ['x','y','z'])\n",
    "        df = pd.concat([df_left,df_right],axis = 1, join = 'outer') \n",
    "        df_linker = pd.concat([df_linker,df],ignore_index=True, join = 'outer')\n",
    "        linker_count += 1\n",
    "    return df_linker\n",
    "\n",
    "linker_count,Residue_name = 1,'TCP'\n",
    "new_beginnings_array,new_linker = center_of_unitbox_points,rotated_new_linker\n",
    "df_linker = calculate_linker(linker_file,linker_cut_count,Residue_name,new_beginnings_array,new_linker)\n",
    "df_linker.to_csv('linker.txt',header=None,sep='\\t',index=False)\n",
    "outgro(df_linker,'linker',0)\n",
    "outxyz('linker',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "body_diag=(dx+dy+dz).ravel() \n",
    "\n",
    "# use a matrix to find body diagnol describe saturation of points \n",
    "def points_connectivity_in_box(points,body_diag):\n",
    "    points_connect_matrix = np.zeros((points.shape[0],points.shape[0]))\n",
    "    points_along_dx_matrix = np.zeros((points.shape[0],points.shape[0]))\n",
    "    for i in range(points.shape[0]):\n",
    "        for j in range(i,points.shape[0]):\n",
    "            ij = points[j]-points[i]\n",
    "            if  (np.abs(ij)==body_diag).all(): \n",
    "                points_connect_matrix[i][j] = 1\n",
    "    return points_connect_matrix,points_along_dx_matrix\n",
    "points_connect_matrix,points_along_dx_matrix= points_connectivity_in_box(points,body_diag)\n",
    "print(points_connect_matrix)\n",
    "pairs_body_diag_matrix = np.argwhere(points_connect_matrix)\n",
    "pairA1_index = pairs_body_diag_matrix[:,0]\n",
    "pairA2_index = pairs_body_diag_matrix[:,1]\n",
    "body_centers = np.reshape((points[pairA1_index[0]]+points[pairA2_index[0]])/2,(1,3))\n",
    "for i in range(1,len(pairA1_index)):\n",
    "    body_center = (points[pairA1_index[i]]+points[pairA2_index[i]])/2\n",
    "    body_center = np.reshape(body_center,(1,3))\n",
    "    body_centers=np.concatenate((body_centers,body_center),axis =0)\n",
    "unique_body_center = np.unique((body_centers),axis = 0)\n",
    "#print(body_centers,unique_body_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distance_points_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#NOTE: to be removed this cell is for searching by distance criteria\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m distance_points_array \u001b[38;5;241m=\u001b[39m \u001b[43mdistance_points_array\u001b[49m\n\u001b[1;32m      3\u001b[0m unique_distance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(distance_points_array)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(unique_distance)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'distance_points_array' is not defined"
     ]
    }
   ],
   "source": [
    "#NOTE: to be removed this cell is for searching by distance criteria\n",
    "distance_points_array = distance_points_array\n",
    "unique_distance = np.unique(distance_points_array).tolist()\n",
    "print(unique_distance)\n",
    "indices = np.where(distance_points_array == unique_distance[6]) #TODO:variable\n",
    "pairAB=[]\n",
    "for i in range(indices[0].shape[0]):\n",
    "    pairAB.append(np.array([points[indices[0][i]],points[indices[1][i]]]))\n",
    "print(pairAB)\n",
    "\n",
    "\n",
    "##TODO:pairAB[i][1][0]\n",
    "#A_res_Al=df1_node[(df1_node['x']==pairAB[0][0][0])&(df1_node['y']==pairAB[0][0][1])&(df1_node['z']==pairAB[0][0][2])             \n",
    "#               ].reset_index(drop=True)\n",
    "#\n",
    "#A_resnum = A_res_Al.loc[0,'Res_number']\n",
    "#\n",
    "#B_res_Al=df1_node[(df1_node['x']==pairAB[0][1][0])&(df1_node['y']==pairAB[0][1][1])&(df1_node['z']==pairAB[0][1][2])             \n",
    "#               ].reset_index(drop=True)\n",
    "#B_resnum = B_res_Al.loc[0,'Res_number']\n",
    "#\n",
    "#A_res = df1_node[df1_node['Res_number']==A_resnum].reset_index(drop=True)\n",
    "#B_res = df1_node[df1_node['Res_number']==B_resnum].reset_index(drop=True)\n",
    "#v_AB = B_res.loc[0, ['x','y','z']].to_numpy()-A_res.loc[0, ['x','y','z']].to_numpy()\n",
    "##print(A_res,B_res,v_AB)\n",
    "#AB_res = pd.concat([A_res,B_res],axis =0,join='outer')\n",
    "#\n",
    "#def calculate_distance(A,B,X):\n",
    "#   AX=X-A\n",
    "#   l_AB=np.linalg.norm(B-A)\n",
    "#   vAB = (B-A)/l_AB\n",
    "#   Y=np.dot(AX,vAB)*vAB+A\n",
    "#   d = np.linalg.norm(Y-X)\n",
    "#   return d\n",
    "#\n",
    "#def add_distance2residue(df,A,B):\n",
    "#   xyz = np.asarray(df.loc[:,['x','y','z']])\n",
    "#   d_df= pd.DataFrame(np.zeros((xyz.shape[0], 1)),columns = ['distance'])\n",
    "#   for i in range(xyz.shape[0]):\n",
    "#       d_df.loc[i,'distance'] = calculate_distance(A,B,xyz[i])\n",
    "#   df = pd.concat([df.reset_index(drop = True),d_df],axis = 1, join = 'outer')\n",
    "#   return df\n",
    "#\n",
    "#AB_res = add_distance2residue(AB_res,pairAB[0][0],pairAB[0][1])\n",
    "#distance_list_of_surroundings = []\n",
    "#distance_list_of_surroundings = AB_res['distance'].to_list()\n",
    "#distance_list_of_surroundings.sort()\n",
    "#print(distance_list_of_surroundings[2:6])\n",
    "#AB_res[(AB_res['distance']>0.9*distance_list_of_surroundings[2])&(AB_res['distance']<1.1*distance_list_of_surroundings[5])]\n",
    "#guide_atoms_in_AB = AB_res[(AB_res['distance']>0.9*distance_list_of_surroundings[2])\n",
    "#                           &(AB_res['distance']<1.1*distance_list_of_surroundings[5])].reset_index(drop=True)\n",
    "#print(guide_atoms_in_AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3 16 16]\n"
     ]
    }
   ],
   "source": [
    "cut_template=readpdb('all.pdb')\n",
    "print(body_diag)\n",
    "cut_template['x']=cut_template['x']-3\n",
    "cut_template['y']=cut_template['y']-16\n",
    "cut_template['z']=cut_template['z']-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Atom_label Residue  Res_number      x      y      z Note\n",
      "3          O2     TCP          64 -0.394 -0.997  0.980    O\n",
      "4         C45     TCP          64 -1.531 -1.366  1.373    C\n",
      "5          O3     TCP          64 -2.668 -0.974  1.004    O\n",
      "17          O     TCP          70  0.391  0.972 -1.004    O\n",
      "18        C44     TCP          70  1.529  1.367 -1.370    C\n",
      "19         O1     TCP          70  2.665  1.000 -0.977    O\n"
     ]
    }
   ],
   "source": [
    "#print(cut_template)\n",
    "cut = cut_template[(cut_template['x']> (-3))&(cut_template['y']> (-3))&(cut_template['z']> (-3))\\\n",
    "                   &(cut_template['x']< 3)&(cut_template['y']< 3)&(cut_template['z'] < 3)\\\n",
    "                    &(cut_template['Residue']=='TCP')].reset_index(drop=True)\n",
    "\n",
    "cut =cut[(cut['Atom_label']=='O2') | (cut['Atom_label']=='O3') | (cut['Atom_label']=='C45')|\\\n",
    "         (cut['Atom_label']=='O1') | (cut['Atom_label']=='O') | (cut['Atom_label']=='C44')]\n",
    "print(cut)\n",
    "cut.to_csv('cut.txt',header=None,sep='\\t',index=False)\n",
    "#outgro(cut,'cut',0)\n",
    "#outxyz('cut',0)\n",
    "def calculate_user_deifined_termination(He,Cut_in_linker,input,index,d):\n",
    "    He_points = np.array(He.loc[:, ['x','y','z']])\n",
    "    Y = He_points[0]\n",
    "    farthest_atom = find_farthest_point_in_cutoff(Cut_in_linker,Y)\n",
    "    FA = np.array(farthest_atom.loc[['x','y','z']])\n",
    "    Y_FA= FA-Y\n",
    "    oldC = np.array(input.loc[index-1, ['x','y','z']])\n",
    "    newC= FA+d*normalize_vector(Y_FA)\n",
    "    translation = newC-oldC\n",
    "    \n",
    "    extra = input.loc[:,['x','y','z']]+translation\n",
    "    #extra_df = pd.DataFrame(extra,columns=['x','y','z'])\n",
    "    input['x']= extra['x']\n",
    "    input['y']= extra['y']\n",
    "    input['z']= extra['z']S\n",
    "    input['Residue'] = 'CUT'\n",
    "    #print(input)\n",
    "    return input\n",
    "\n",
    "Cut_in_linker = MOF_build.build.find_points_in_cutoff(L_filename, point_A, point_B, cutoff).reset_index(drop=True) \n",
    " \n",
    "Extra = MOF_build.build.calculate_user_deifined_termination(M_filename,Cut_in_linker,extra_termination,extra_point_index,distance_extra_terimination)\n",
    "PMMP_file = pd.concat([Cut_in_linker,Extra], ignore_index=True).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
