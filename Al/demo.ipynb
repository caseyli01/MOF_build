{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import quaternion\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "\n",
    "x_num,y_num,z_num,dx_value,dy_value,dz_value =2,2,2,3,16,16\n",
    "\n",
    "def readpdb(pdb):\n",
    "    inputfile = str(pdb)\n",
    "    outputfile = inputfile.strip(\".pdb\")\n",
    "    with open(inputfile,'r') as fp:\n",
    "        content = fp.readlines()\n",
    "        linesnumber = len(content)\n",
    "    lines = [] \n",
    "    with open(outputfile+'.txt','w') as fp_w:\n",
    "        for i in range (linesnumber):\n",
    "            values = content[i].split() if content[i].strip() != '' else None\n",
    "            if values == None:\n",
    "                continue\n",
    "            if (values[0]=='ATOM' or values[0] == 'HETATM'):\n",
    "                value1 = values[2] #atom_label\n",
    "                value2 = values[3] #res_name\n",
    "                value3 = float(values[5]) #x\n",
    "                value4 = float(values[6]) #y\n",
    "                value5 = float(values[7]) #z\n",
    "                value6 = values[10] #atom_note\n",
    "                value7 = int(values[4])\n",
    "                newline = \"%7s%7s%5d%8.3f%8.3f%8.3f%7s\" % (\n",
    "                    value1, value2, value7,value3, value4, value5, value6\n",
    "                    )\n",
    "     \n",
    "                lines.append(newline+'\\n')\n",
    "        fp_w.writelines(lines)\n",
    "    data = pd.read_csv(outputfile+'.txt',sep='\\s+',names=['Atom_label','Residue','Res_number','x','y','z','Note'])\n",
    "    return data\n",
    "\n",
    "def normalize_vector(v):\n",
    "    norm_v=v/np.linalg.norm(v)\n",
    "    return norm_v\n",
    "\n",
    "'''pre-process'''\n",
    "def get_axis2(solution_1_2,arr_1_2,solution_1_3,arr_1_3):\n",
    "    axis1 = np.dot(solution_1_2,arr_1_2)\n",
    "    axis2 = np.dot(solution_1_3,arr_1_3)\n",
    "    q_axis = calculate_q_rotation_with_vectors(axis1,axis2)\n",
    "    dx = np.array([1,0,0])\n",
    "    axis0=quaternion.from_vector_part(dx)\n",
    "    new_axis = q_axis*axis0\n",
    "    new_axis_vector = quaternion.as_vector_part(new_axis)\n",
    "    print(new_axis_vector)\n",
    "    return new_axis_vector\n",
    "\n",
    "def points_generator(x_num,y_num,z_num,dx_value,dy_value,dz_value): \n",
    "    '''this function is to generate a group of 3d SCATTER defined by user for further grouping points'''\n",
    "    dx = dx_value*np.array([[1,0,0]]) #dx_value works as a scalar\n",
    "    dy = dy_value*np.array([[0,1,0]])\n",
    "    dz = dz_value*np.array([[0,0,1]])\n",
    "    # add x layer\n",
    "    points = np.array([[0,0,0]])\n",
    "    for i in range(0,x_num+1):\n",
    "        points = np.concatenate((points,i*dx),axis=0)\n",
    "    # add y layer\n",
    "    points_x =points\n",
    "    for i in range(0,y_num+1):\n",
    "        points = np.concatenate((points,points_x+i*dy),axis = 0)\n",
    "    # add z layer \n",
    "    points_xy = points\n",
    "    for i in range(0,z_num+1):\n",
    "        points = np.concatenate((points,points_xy+i*dz),axis = 0)\n",
    "    points = np.unique(points, axis = 0)\n",
    "    return points\n",
    "\n",
    "def find_overlapped_3D_array(array1,array2):\n",
    "    set1 = set(map(tuple, array1.reshape(-1, array1.shape[-1])))\n",
    "    set2 = set(map(tuple, array2.reshape(-1, array2.shape[-1])))\n",
    "    # Find intersection of sets\n",
    "    overlapped_elements = set1.intersection(set2)\n",
    "    # Convert back to numpy array\n",
    "    overlapped_array = np.array(list(overlapped_elements)).reshape(-1, array1.shape[-1])\n",
    "    return overlapped_array\n",
    "\n",
    "def find_solution(pAl1,pAl2,pAl1_1,pAl1_2,pAl1_3):\n",
    "    Al1_Al2 = pAl2-pAl1\n",
    "    vAl1_Al2 = normalize_vector(Al1_Al2)\n",
    "    v12_1,v12_2,v12_3  = pAl1_1-pAl1,pAl1_2-pAl1,pAl1_3-pAl1\n",
    "    v12_1,v12_2,v12_3= normalize_vector(v12_1),normalize_vector(v12_2),normalize_vector(v12_3)                        \n",
    "    arr_1_2=np.vstack((v12_1,v12_2,v12_3))\n",
    "    arr_1_2 = arr_1_2.astype(np.float64)\n",
    "    vAl1_Al2 = vAl1_Al2.astype(np.float64)\n",
    "    solution_1_2=np.dot(vAl1_Al2,np.linalg.inv(arr_1_2))\n",
    "    return solution_1_2,arr_1_2\n",
    "\n",
    "'''rotate'''\n",
    "def calculate_q_rotation_with_vectors(p1,p2):\n",
    "    q1 = quaternion.from_vector_part(p1)\n",
    "    q2 = quaternion.from_vector_part(p2)\n",
    "    r = q2*q1.inverse()\n",
    "    return r\n",
    "\n",
    "def get_rotated_array(arr,q):\n",
    "    q_arr= quaternion.from_vector_part(arr)\n",
    "    rotated_q_arr = q*q_arr*q.inverse()\n",
    "    rotated_arr = quaternion.as_vector_part(rotated_q_arr)\n",
    "    return rotated_arr\n",
    "\n",
    "def calculate_q_rotation_with_axis_degree(axis,theta): #axis is HE---HE ,theta from O1--AXIS--O1'\n",
    "    w = theta/2\n",
    "    s = np.sin(w)\n",
    "    q_real= np.array([np.cos(w)])\n",
    "    q_ijk = s*axis\n",
    "    q_r = np.concatenate([q_real,q_ijk])\n",
    "    q_r = quaternion.from_float_array(q_r)\n",
    "    return q_r\n",
    "\n",
    "def rotate_twice_linker(df_input,beginning_point,v1_file,v1_frame,v2_file,v2_frame):\n",
    "    arr = df_input.loc[:,['x','y','z']].to_numpy() - beginning_point #MOVE center (Al this case) to (0,0,0)\n",
    "    q1 = calculate_q_rotation_with_vectors(v1_file,v1_frame) \n",
    "    q_V2 = quaternion.from_vector_part(v2_file)\n",
    "    new_q_V2 = q1*q_V2\n",
    "    new_V2_file = quaternion.as_vector_part(new_q_V2)\n",
    "    #angle = calculate_angle_rad(v1_frame,new_V2_file,v2_frame)\n",
    "    #q2 = calculate_q_rotation_with_axis_degree(v1_frame,angle)\n",
    "    q2 = calculate_q_rotation_with_vectors(new_V2_file,v2_frame)\n",
    "    q_rotate = q2*q1\n",
    "    new_array = get_rotated_array(arr,q_rotate)\n",
    "    return new_array\n",
    "\n",
    "'''node linker cut'''\n",
    "\n",
    "def calculate_node(Metal_file,linker_cut_count,Residue_name,group_A,group_B,new_node_A,new_node_B):\n",
    "#rotate as group, translate as group \n",
    "    Metal_count = linker_cut_count\n",
    "    zero_lines = new_node_A.shape[0]\n",
    "    df_node = pd.DataFrame()\n",
    "    for i in group_A:\n",
    "        new_positions=new_node_A+i\n",
    "        df_left = pd.DataFrame(np.zeros((zero_lines, 4)),columns = ['Atom_label','Residue','Res_number','Note'])\n",
    "        df_left['Atom_label'] = Metal_file['Atom_label']\n",
    "        df_left['Residue'] = Metal_file['Residue']\n",
    "        df_left['Res_number'] = Metal_count\n",
    "        df_left['Note'] = Metal_file['Note']\n",
    "        df_right = pd.DataFrame(new_positions,columns = ['x','y','z'])\n",
    "        df = pd.concat([df_left,df_right],axis = 1, join = 'outer') \n",
    "        df_node = pd.concat([df_node,df],ignore_index=True, join = 'outer')\n",
    "        Metal_count += 1\n",
    "    for i in group_B:\n",
    "        new_positions=new_node_B+i\n",
    "        df_left = pd.DataFrame(np.zeros((zero_lines, 4)),columns = ['Atom_label','Residue','Res_number','Note'])\n",
    "        df_left['Atom_label'] = Metal_file['Atom_label']\n",
    "        df_left['Residue'] = Metal_file['Residue']\n",
    "        df_left['Res_number'] = Metal_count\n",
    "        df_left['Note'] = Metal_file['Note']\n",
    "        df_right = pd.DataFrame(new_positions,columns = ['x','y','z'])\n",
    "        df = pd.concat([df_left,df_right],axis = 1, join = 'outer') \n",
    "        df_node = pd.concat([df_node,df],ignore_index=True, join = 'outer')\n",
    "        Metal_count += 1\n",
    "    \n",
    "    return df_node\n",
    "\n",
    "def calculate_linker(linker_file,linker_count,Residue_name,new_beginnings_array,new_linker):\n",
    "#translate by center points position, beginning point as CENTER OF PORPHYRIN like Co(body center of unit box)\n",
    "    zero_lines = new_linker.shape[0]\n",
    "    df_linker = pd.DataFrame()\n",
    "    for i in new_beginnings_array:\n",
    "        new_positions=new_linker+i\n",
    "        df_left = pd.DataFrame(np.zeros((zero_lines, 4)),columns = ['Atom_label','Residue','Res_number','Note'])\n",
    "        df_left['Atom_label'] = linker_file['Atom_label']\n",
    "        df_left['Residue'] = linker_file['Residue']\n",
    "        df_left['Res_number'] = linker_count\n",
    "        df_left['Note'] = linker_file['Note']\n",
    "        df_right = pd.DataFrame(new_positions,columns = ['x','y','z'])\n",
    "        df = pd.concat([df_left,df_right],axis = 1, join = 'outer') \n",
    "        df_linker = pd.concat([df_linker,df],ignore_index=True, join = 'outer')\n",
    "        linker_count += 1\n",
    "    return df_linker\n",
    "\n",
    "'''output'''\n",
    "\n",
    "def outgro(df_all,output,Hecount):\n",
    "    with open(output+'.txt', 'r') as f:\n",
    "        # Read the lines from the file\n",
    "        lines = f.readlines()\n",
    "        atoms_number = len(lines)\n",
    "    newgro = []\n",
    "    with open(output+'.gro', 'w') as fp:\n",
    "        newgro.append(\"generated by MOF_BUILD\"+'\\n'+str(atoms_number-Hecount)+'\\n')\n",
    "        for i in range (Hecount,atoms_number):\n",
    "            values = lines[i].split()\n",
    "            value_atom_number = int(i+1-Hecount) #atom_number\n",
    "            value_label = values[0] #atom_label\n",
    "            value_resname = values[1] #residue_name\n",
    "            value_resnumber = int(values[2]) #residue number\n",
    "            value_x = float(values[4])/10 #x      \n",
    "            value_y = float(values[5])/10 #y\n",
    "            value_z = float(values[6])/10 #z\n",
    "            formatted_line = \"%5d%-5s%5s%5d%8.4f%8.4f%8.4f\" % (\n",
    "                        value_resnumber, value_resname, value_label, value_atom_number, value_x, value_y, value_z) \n",
    "            newgro.append(formatted_line+'\\n')        \n",
    "        tail = '5 5 5 \\n'\n",
    "        newgro.append(tail)\n",
    "        fp.writelines(newgro)\n",
    "\n",
    "def outxyz(output,Hecount):\n",
    "    with open(output+'.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        atoms_number = len(lines)-Hecount\n",
    "    newxyz = []\n",
    "    with open(output+'.xyz', 'w') as fp:\n",
    "        newxyz.append(str(atoms_number)+'\\n'+\"generated by MOF_BUILD\"+'\\n')\n",
    "        for i in range (Hecount,atoms_number):\n",
    "            values = lines[i].split()\n",
    "            value_label = values[0] #atom_label\n",
    "            value_label = re.sub(r'\\d', '', value_label)\n",
    "            value_x = float(values[4]) #x      \n",
    "            value_y = float(values[5]) #y\n",
    "            value_z = float(values[6]) #z\n",
    "            formatted_line = \"%-5s%8.3f%8.3f%8.3f\" % (\n",
    "                        value_label, value_x, value_y, value_z\n",
    "            )        \n",
    "            newxyz.append(formatted_line+'\\n')        \n",
    "        fp.writelines(newxyz)\n",
    "\n",
    "def outpdb(output,Hecount):\n",
    "    with open(output+'.txt', 'r') as f:\n",
    "    # Read the lines from the file\n",
    "        lines = f.readlines()\n",
    "        atoms_number = len(lines)\n",
    "\n",
    "    newpdb = []\n",
    "    with open(output+'.txt', 'w') as fp:\n",
    "        # Iterate over each line in the input file\n",
    "        for i in range (atoms_number):\n",
    "            # Split the line into individual values (assuming they are separated by spaces)\n",
    "            values = lines[i].split()\n",
    "            # Extract values based on their positions in the format string\n",
    "            value1 = 'ATOM'\n",
    "            value2 = int(i+1-Hecount)\n",
    "            value3 = values[0] #label\n",
    "            value4 = values[1] #residue\n",
    "            value5 = int(values[2]) #residue number\n",
    "            value6 = float(values[4]) #x      \n",
    "            value7 = float(values[5]) #y\n",
    "            value8 = float(values[6]) #z\n",
    "            value9 = '1.00'\n",
    "            value10 = '0.00'\n",
    "            value11 = values[3] #note\n",
    "            # Format the values using the specified format string\n",
    "            formatted_line = \"%-6s%5d%5s%4s%10d%8.3f%8.3f%8.3f%6s%6s%7s\" % (\n",
    "                        value1, value2, value3, value4, value5, value6, value7, value8,value9,value10,value11\n",
    "            )        \n",
    "            lines[i] = formatted_line+'\\n'        \n",
    "        fp.writelines(lines)\n",
    "\n",
    "    with open(output+'.pdb', 'w') as fp:\n",
    "        # Iterate over each line in the input file\n",
    "        newpdb.append(\"generated by MOF_BUILD\"+'\\n')\n",
    "        newpdb.append(lines[Hecount])\n",
    "        for i in range (Hecount+1,len(lines)):\n",
    "            lastline = lines[i-1]\n",
    "            thisline = lines[i]\n",
    "            # Split the line into individual values (assuming they are separated by spaces)\n",
    "            old_residue_number = lastline.split()[4]\n",
    "            new_residue_number = thisline.split()[4]\n",
    "            \n",
    "            if(old_residue_number != new_residue_number):\n",
    "                newline ='TER'+'\\n'+thisline\n",
    "            else:\n",
    "                newline = thisline\n",
    "                newpdb.append(newline)\n",
    "        fp.writelines(newpdb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.90910488 -0.29143599  0.31053338] [ 0.03987703 -0.74301673 -0.725923  ]\n",
      "[ 1.00000000e+00 -5.55111512e-17  5.55111512e-17] [ 5.55111512e-17 -5.55111512e-17 -1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "textbook_Metal_file = readpdb('Al_Al.pdb')\n",
    "pAl1,pAl2,pAl3 = (textbook_Metal_file.loc[15, ['x','y','z']].to_numpy(),\n",
    "                  textbook_Metal_file.loc[8, ['x','y','z']].to_numpy(),\n",
    "                  textbook_Metal_file.loc[29, ['x','y','z']].to_numpy())    \n",
    "pAl1_1,pAl1_2,pAl1_3 =(textbook_Metal_file.loc[16, ['x','y','z']].to_numpy(),\n",
    "                          textbook_Metal_file.loc[17, ['x','y','z']].to_numpy(),\n",
    "                          textbook_Metal_file.loc[18, ['x','y','z']].to_numpy()) \n",
    "solution_1_2,arr_1_2 = find_solution(pAl1,pAl2,pAl1_1,pAl1_2,pAl1_3)\n",
    "solution_1_3,arr_1_3 = find_solution(pAl1,pAl3,pAl1_1,pAl1_2,pAl1_3)\n",
    "print(solution_1_2,solution_1_3)\n",
    "print(np.dot(solution_1_2,arr_1_2),np.dot(solution_1_3,arr_1_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00 -5.55111512e-17 -1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "Metal_file=readpdb('test.pdb')\n",
    "axis1 = np.array([1,0,0])\n",
    "axis2 =  get_axis2(solution_1_2,arr_1_2,solution_1_3,arr_1_3)\n",
    "axis3 = np.cross(axis1,axis2)\n",
    "\n",
    "point_Al = Metal_file.loc[0, ['x','y','z']].to_numpy()\n",
    "p1,p2,p3 = (Metal_file.loc[1, ['x','y','z']].to_numpy()- point_Al,\n",
    "                                    Metal_file.loc[2, ['x','y','z']].to_numpy()- point_Al,\n",
    "                                    Metal_file.loc[3, ['x','y','z']].to_numpy()- point_Al )     \n",
    "p1,p2,p3=normalize_vector(p1),normalize_vector(p2),normalize_vector(p3)                         \n",
    "arr = np.vstack((p1,p2,p3))\n",
    "V1,V2 = np.dot(solution_1_2,arr),np.dot(solution_1_3,arr)\n",
    "V1,V2 = normalize_vector(V1),normalize_vector(V2)\n",
    "\n",
    "Al_node = Metal_file.loc[:,['x','y','z']].to_numpy() - point_Al  #MOVE center (Al this case) to (0,0,0)\n",
    "q1 = calculate_q_rotation_with_vectors(V1,axis1) \n",
    "q_V2 = quaternion.from_vector_part(V2)\n",
    "new_q_V2 = q1*q_V2\n",
    "new_V2 = quaternion.as_vector_part(new_q_V2)\n",
    "#angle = calculate_angle_rad(axis1,new_V2,axis2)\n",
    "#print(new_V2,axis2,angle)\n",
    "#q2 = calculate_q_rotation_with_axis_degree(axis1,angle)\n",
    "q2 = calculate_q_rotation_with_vectors(new_V2,axis2)\n",
    "#q3 = quaternion.from_float_array([0,0,0,-1])\n",
    "#dy dz rotate pi\n",
    "q3 = calculate_q_rotation_with_axis_degree(axis2,np.pi)*calculate_q_rotation_with_axis_degree(axis3,np.pi)\n",
    "q_A = q2*q1\n",
    "q_B = q3*q2*q1\n",
    "\n",
    "new_node_A = get_rotated_array(Al_node,q_A)\n",
    "new_node_B = get_rotated_array(Al_node,q_B)\n",
    "\n",
    "#df_node.to_csv('node.txt',header=None,sep='\\t',index=False)\n",
    "\n",
    "#outgro(df_node,'node',0)\n",
    "#outxyz('node',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 3) (12, 3) (27, 3)\n"
     ]
    }
   ],
   "source": [
    "#x_num,y_num,z_num,dx_value,dy_value,dz_value = 4,4,4,3.51,15.14,16.36\n",
    "#x_num,y_num,z_num,dx_value,dy_value,dz_value = 2,3,3,3,16,16\n",
    "dx = dx_value*np.array([1,0,0]) #dx_value works as a scalar\n",
    "dy = dy_value*np.array([0,1,0])\n",
    "dz = dz_value*np.array([0,0,1])\n",
    "\n",
    "points = points_generator(x_num,y_num,z_num,dx_value,dy_value,dz_value)\n",
    "#Amap needs to decribe all A in single unit box\n",
    "A_map_0 =  points_generator(x_num,y_num,z_num,2*dx_value,2*dy_value,dz_value)\n",
    "A_map_1 = A_map_0+dx+dy\n",
    "A_map = np.concatenate((A_map_0,A_map_1),axis=0)\n",
    "B_map_0, B_map_1 = A_map+dx, A_map+dy\n",
    "B_map = np.concatenate((B_map_0,B_map_1),axis=0)\n",
    "A_map,B_map = np.unique(A_map,axis=0),np.unique(B_map,axis=0)\n",
    "group_A = find_overlapped_3D_array(A_map,points)\n",
    "group_B = find_overlapped_3D_array(B_map,points)\n",
    "print(group_A.shape,group_B.shape,points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "linker_cut_count,Residue_name = 1,'Al'\n",
    "df_node = calculate_node(Metal_file,linker_cut_count,Residue_name,group_A,group_B,new_node_B,new_node_A)\n",
    "df1_node = df_node[df_node['Residue']=='AL6'].reset_index(drop=True)\n",
    "df1_node['Res_number']= (df1_node.index//7+1)\n",
    "df2_node = df_node[df_node['Residue']=='MOH'].reset_index(drop=True)\n",
    "df2_node['Res_number']= (df2_node.index//2+1)+27\n",
    "df12_node = pd.concat([df1_node,df2_node],join='outer',ignore_index=True,axis=0)\n",
    "df12_node.to_csv('node.txt',header=None,sep='\\t',index=False)\n",
    "outgro(df_node,'node',0)\n",
    "outxyz('node',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_diag=(dx+dy+dz).ravel() \n",
    "points_c = find_overlapped_3D_array(group_A+body_diag,points)\n",
    "center_of_Aunitbox_points = points_c-0.5*body_diag #Co position \n",
    "\n",
    "'''\n",
    "rotate porphyrin or other tetradentate linker to make it algin with dx and make Co position as parameter for 2nd rotate\n",
    "for further translation \n",
    "\n",
    "'''\n",
    "linker_file = readpdb('TCP.pdb')\n",
    "#O1 is the cross point\n",
    "O1,O2,O3 = linker_file.loc[54,['x','y','z']].to_numpy(),\\\n",
    "            linker_file.loc[57,['x','y','z']].to_numpy(),\\\n",
    "            linker_file.loc[51,['x','y','z']].to_numpy()\n",
    "Co = linker_file.loc[60,['x','y','z']].to_numpy()\n",
    "r1_vector_in_frame = normalize_vector(dx)\n",
    "r2_vector_in_frame = normalize_vector(dz)\n",
    "r1_vector_in_linker = normalize_vector(O2-O1)\n",
    "r2_vector_in_linker = normalize_vector(O3-O1)\n",
    "\n",
    "df_input = linker_file\n",
    "beginning_point = O1\n",
    "v1_file = r1_vector_in_linker\n",
    "v1_frame = r1_vector_in_frame\n",
    "v2_file = r2_vector_in_linker\n",
    "v2_frame = r2_vector_in_frame\n",
    "\n",
    "new_linker = rotate_twice_linker(df_input,beginning_point,v1_file,v1_frame,v2_file,v2_frame)\n",
    "rotated_new_linker = new_linker-new_linker[60] #FIXME: make Co in beginning \n",
    "\n",
    "\n",
    "linker_count,Residue_name = 55,'TCP'\n",
    "new_beginnings_array,new_linker = center_of_Aunitbox_points,rotated_new_linker\n",
    "\n",
    "df_linker = calculate_linker(linker_file,linker_count,Residue_name,new_beginnings_array,new_linker)\n",
    "df_linker.to_csv('linker.txt',header=None,sep='\\t',index=False)\n",
    "outgro(df_linker,'linker',0)\n",
    "outxyz('linker',0)\n",
    "\n",
    "df_all = pd.concat([df12_node,df_linker],ignore_index=True, join = 'outer')\n",
    "df_all.to_csv('all.txt', sep='\\t', header = None, index = False)\n",
    "outgro(df_all,'all',0)\n",
    "outxyz('all',0)\n",
    "outpdb('all',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Atom_label Residue  Res_number      x      y      z Note\n",
      "10         O6     TCP          56  2.633  0.980  0.991    O\n",
      "11        C47     TCP          56  1.497  1.356  1.382    C\n",
      "12         O7     TCP          56  0.358  0.968  1.014    O\n",
      "  Atom_label Residue  Res_number      x      y      z Note\n",
      "0         H1     UNK           1 -1.816  2.528  3.614    H\n",
      "1         H2     UNK           1 -1.559  0.891  2.965    H\n",
      "2         H3     UNK           1 -1.817  2.258  1.855    H\n",
      "[0.00278569 0.70942163 0.70477882] [ 0.9861186   0.16404761 -0.02566108] [-0.9999349900376134 -0.005274382365033766 0.010109232866314197] [0.08305453069948407 -0.6186913673590481 -0.7812316793920226]\n",
      "[[1.50131781 2.45560353 2.47440717]\n",
      " [1.22803198 3.08926675 1.63058149]\n",
      " [0.9726611  2.79074858 3.36629219]\n",
      " [1.22734439 1.4232406  2.25615194]]\n",
      "  Atom_label Residue  Res_number         x         y         z Note\n",
      "0         C1     UNK           1  1.501318  2.455604  2.474407    C\n",
      "1         H1     UNK           1  1.228032  3.089267  1.630581    H\n",
      "2         H2     UNK           1  0.972661  2.790749  3.366292    H\n",
      "3         H3     UNK           1  1.227344  1.423241  2.256152    H\n",
      "   Atom_label Residue  Res_number Note         x         y         z\n",
      "0          O6     TCP          56    O  2.633000  0.980000  0.991000\n",
      "1         C47     TCP          56    C  1.497000  1.356000  1.382000\n",
      "2          O7     TCP          56    O  0.358000  0.968000  1.014000\n",
      "3          C1     UNK           1    C  1.501318  2.455604  2.474407\n",
      "4          H1     UNK           1    H  1.228032  3.089267  1.630581\n",
      "5          H2     UNK           1    H  0.972661  2.790749  3.366292\n",
      "6          H3     UNK           1    H  1.227344  1.423241  2.256152\n",
      "7          O6     TCP          56    O  2.633000  0.980000  0.991000\n",
      "8         C47     TCP          56    C  1.497000  1.356000  1.382000\n",
      "9          O7     TCP          56    O  0.358000  0.968000  1.014000\n",
      "10         C1     UNK           1    C  1.501318  2.455604  2.474407\n",
      "11         H1     UNK           1    H  1.228032  3.089267  1.630581\n",
      "12         H2     UNK           1    H  0.972661  2.790749  3.366292\n",
      "13         H3     UNK           1    H  1.227344  1.423241  2.256152\n"
     ]
    }
   ],
   "source": [
    "'''prepare cut termination file in library for pointA!'''\n",
    "\n",
    "\n",
    "cut_template=readpdb('all.pdb')\n",
    "\n",
    "cut_template['x'],cut_template['y'],cut_template['z']=cut_template['x']-dx_value,cut_template['y']-dy_value,cut_template['z']-dz_value\n",
    "cut = cut_template[(cut_template['x']> (-3))&(cut_template['y']> (-3))&(cut_template['z']> (-3))\\\n",
    "                   &(cut_template['x']< 3)&(cut_template['y']< 3)&(cut_template['z'] < 3)\\\n",
    "                    &(cut_template['Residue']=='TCP')].reset_index(drop=True)\n",
    "\n",
    "cut =cut[(cut['Atom_label']=='O6') | (cut['Atom_label']=='O7') | (cut['Atom_label']=='C47')]\n",
    "connected_atom_C = cut[cut['Note']=='C'].reset_index(drop=True)\n",
    "connected_atom_O = cut[cut['Note']!='C'].reset_index(drop=True)\n",
    "print(cut)\n",
    "extra = readpdb('CH3.pdb')\n",
    "extraH = extra[(extra['Note']=='H')].reset_index(drop=True)\n",
    "print(extraH)\n",
    "CO2_center_O = np.mean(connected_atom_O.loc[:,['x','y','z']].to_numpy(), axis=0)\n",
    "CO2_C = cut[cut['Note']=='C'].loc[:,['x','y','z']].to_numpy()\n",
    "CH3_center_H = np.mean(extraH.loc[:,['x','y','z']].to_numpy(), axis=0)\n",
    "CH3_C = (extra[(extra['Note']=='C')]).loc[:,['x','y','z']].to_numpy()\n",
    "\n",
    "\n",
    "#O---C\n",
    "vector1 = (CO2_C-CO2_center_O).ravel() #target\n",
    "vector2 = (CH3_C-CH3_center_H).ravel()\n",
    "\n",
    "vector3 = CO2_center_O-connected_atom_O.loc[0,['x','y','z']].to_numpy() # (O_C-O1) target\n",
    "vector4 = CH3_center_H-extraH.loc[0,['x','y','z']].to_numpy()\n",
    "\n",
    "vector1,vector2,vector3,vector4 = normalize_vector(vector1),normalize_vector(vector2),normalize_vector(vector3),normalize_vector(vector4)\n",
    "#C---H \n",
    "print(vector1,vector2,vector3,vector4)\n",
    "new_extra_xyz = rotate_twice_linker(extra,CH3_C,vector2,dx,vector4,dy)+1.55*vector1+CO2_C\n",
    "print(new_extra_xyz)\n",
    "extra.loc[:,['x','y','z']] = new_extra_xyz \n",
    "print(extra)\n",
    "\n",
    "defined_term_half1 = pd.concat([cut,extra], axis=0,ignore_index=True).reset_index(drop=True)\n",
    "defined_term_half2 = pd.concat([cut,extra], axis=0,ignore_index=True).reset_index(drop=True)\n",
    "defined_term_half2.loc[:,['x','y','z']] = 1*defined_term_half1.loc[:,['x','y','z']].to_numpy()\n",
    "defined_term = pd.concat([defined_term_half1,defined_term_half2], ignore_index=True).reset_index(drop=True)\n",
    "#print(defined_term)\n",
    "df_left = defined_term.loc[:,['Atom_label','Residue','Res_number','Note']]\n",
    "df_right = defined_term.loc[:,['x','y','z']]\n",
    "cut_term = pd.concat([df_left,df_right],axis=1)\n",
    "cut_term.to_csv('cut.txt',header=None,sep='\\t',index=False)\n",
    "#outgro(defined_term,'cut',0)\n",
    "outxyz('cut',0)\n",
    "\n",
    "print(cut_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378, 3) 189.0 (6, 3)\n",
      "(378, 4) (378, 3)\n"
     ]
    }
   ],
   "source": [
    "x_max,y_max,z_max = x_num*dx_value,y_num*dy_value,z_num*dz_value\n",
    "x_min,y_min,z_min = 0,0,0\n",
    "x_max_series_groupA,x_max_series_groupB = group_A[group_A[:, 0] == x_max],group_B[group_B[:, 0] == x_max]\n",
    "y_max_series_groupA,y_max_series_groupB = group_A[group_A[:, 1] == y_max],group_B[group_B[:, 1] == y_max]\n",
    "z_max_series_groupA,z_max_series_groupB = group_A[group_A[:, 2] == z_max],group_B[group_B[:, 2] == z_max]\n",
    "\n",
    "x_min_series_groupA,x_min_series_groupB = group_A[group_A[:, 0] == x_min],group_B[group_B[:, 0] == x_max]\n",
    "y_min_series_groupA,y_min_series_groupB = group_A[group_A[:, 1] == y_min],group_B[group_B[:, 1] == y_min]\n",
    "z_min_series_groupA,z_min_series_groupB = group_A[group_A[:, 2] == z_min],group_B[group_B[:, 2] == z_min]\n",
    "B_A_rotation_matrix = np.array([[-1,0,0],[0,1,0],[0,0,-1]])\n",
    "cut_term_xyz_group_A = cut_term.loc[:,['x','y','z']].to_numpy()\n",
    "cut_term_xyz_group_B = np.dot(cut_term_xyz_group_A,B_A_rotation_matrix)\n",
    "\n",
    "extras = []\n",
    "\n",
    "for i in y_min_series_groupA:\n",
    "    extra_term = cut_term_xyz_group_A[cut_term_xyz_group_A[:, 1] < y_min]+i\n",
    "    extras.append(extra_term)\n",
    "for i in y_max_series_groupA:\n",
    "    extra_term = cut_term_xyz_group_A[cut_term_xyz_group_A[:, 1] < y_max]+i\n",
    "    extras.append(extra_term)\n",
    "for i in z_min_series_groupA:\n",
    "    extra_term = cut_term_xyz_group_A[cut_term_xyz_group_A[:, 2] < z_min]+i\n",
    "    extras.append(extra_term)\n",
    "for i in z_max_series_groupA:\n",
    "    extra_term = cut_term_xyz_group_A[cut_term_xyz_group_A[:, 2] < z_max]+i\n",
    "    extras.append(extra_term)\n",
    "\n",
    "for i in y_min_series_groupB:\n",
    "    extra_term = cut_term_xyz_group_B[cut_term_xyz_group_B[:, 1] < y_min]+i\n",
    "    extras.append(extra_term)\n",
    "for i in y_max_series_groupB:\n",
    "    extra_term = cut_term_xyz_group_B[cut_term_xyz_group_B[:, 1] < y_max]+i\n",
    "    extras.append(extra_term)\n",
    "for i in z_min_series_groupB:\n",
    "    extra_term = cut_term_xyz_group_B[cut_term_xyz_group_B[:, 2] < z_min]+i\n",
    "    extras.append(extra_term)\n",
    "for i in z_max_series_groupB:\n",
    "    extra_term = cut_term_xyz_group_B[cut_term_xyz_group_B[:, 2] < z_max]+i\n",
    "    extras.append(extra_term)\n",
    "\n",
    "extras=np.concatenate(extras,axis=0)\n",
    "print(extras.shape,extras.shape[0]/2,y_min_series_groupA.shape)\n",
    "cut_term['Residue']='CUT'\n",
    "\n",
    "left =[]\n",
    "object_arr = cut_term.loc[:,['Atom_label','Residue','Res_number','Note']].to_numpy()\n",
    "for i in range(int(extras.shape[0]/14)):\n",
    "    left.append(object_arr)\n",
    "df_left= pd.DataFrame((np.concatenate(left,axis=0)),columns= ['Atom_label','Residue','Res_number','Note'])\n",
    "df_left['Res_number']=df_left.index//7+1\n",
    "\n",
    "\n",
    "df_right = pd.DataFrame(extras,columns = ['x','y','z'])\n",
    "df_cut = pd.concat([df_left,df_right],axis = 1, join = 'outer') \n",
    "\n",
    "print(df_left.shape,df_right.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
